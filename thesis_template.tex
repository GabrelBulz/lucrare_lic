 \documentclass[12pt, a4paper]{report}
\special{papersize=210mm, 297mm}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[left=2.5cm, right=2.5cm, top=2.5cm]{geometry}
\renewcommand{\baselinestretch}{1.4}
\usepackage[toc,page]{appendix}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage[export]{adjustbox}
\usepackage{wrapfig}
\graphicspath{{images/} {diagrams/}}

%\usepackage{showframe}
\usepackage{fullpage}

\usepackage{url}
%\usepackage{natbib} % for author-date citation \citep{}, \citet[]
%\usepackage{hyperref}
%\usepackage[nottoc]{tocbibind}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{color}


\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
	 language=java,
	aboveskip=5mm, belowskip=3mm, showstringspaces=false,
	columns=flexible, basicstyle={\small\ttfamily},
	numbers=none, numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}


\usepackage{multirow}
\usepackage{array}
\newcolumntype{L}[1]{> {\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\pagenumbering{roman}

\begin{document}

%======================================================================

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

\vspace{-20pt}
\includegraphics[width=100pt]{FMI-03.png}\\[1.0cm] % Include a department/university logo - this will require the graphicx package
 
\textsc{\LARGE West University of  Timisoara}\\[0.5cm] % Name of your university/college
\textsc{\Large Faculty of Mathematics and Computer Science}\\[0.5cm] % Major heading such as course name
\textsc{\large Study Program: \\Computer Science in English}\\[3cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\textsc{\Huge Bachelor Thesis}\\[5cm]

%\HRule \\[0.5cm]
%{\huge \bfseries Simplified Transport Layer Security}
%\\[0.4cm]
%{\huge \bf implementation}\\[3cm] % Title of your document
%\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

%\textsc{\huge Intermediate Report}

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\textbf{COORDINATOR:}\\
Conf. Dr. Marc Eduard \textsc{Fr\^incu} % Coordinator
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\textbf{GRADUATE:} \\
Bulz \textsc{Gabriel} % Student's Name
\end{flushright}
\end{minipage}\\[1cm]


%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------
\vfill
{\large Timi\c{s}oara \\2018}\\ % Date, change the \today to a set date if you want to be precise

 
%----------------------------------------------------------------------------------------

%\vfill % Fill the rest of the page with whitespace

\end{titlepage}

% =====================================================================

% second title page. as requested by UVT

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

\vspace{3cm}
%\includegraphics[width=100pt]{FMI-03.png}\\[1.0cm] % Include a department/university logo - this will require the graphicx package


\textsc{\LARGE West University of  Timisoara}\\[0.5cm] % Name of your university/college
\textsc{\Large Faculty of Mathematics and Computer Science}\\[0.5cm] % Major heading such as course name
\textsc{\large Study Program: \\Computer Science in English}\\[6cm] % Minor heading such as course title


%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

%\textsc{\Huge Master Dissertation}\\[2cm]

%\HRule \\[0.5cm]
{\Huge \bfseries Prediction of areas with high  }
\\[0.4cm]
{\Huge \bf flooding risk using physical models}\\[5cm] % Title of your document
%\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

%\textsc{\huge Intermediate Report}

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\textbf{COORDINATOR:}\\
Conf. Dr. Marc Eduard \textsc{Fr\^incu} % Coordinator
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\textbf{GRADUATE:} \\
Bulz \textsc{Gabriel} % Student's Name
\end{flushright}
\end{minipage}\\[1cm]

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------
\vfill
{\large Timi\c{s}oara\\ 2018}\\ % Date, change the \today to a set date if you want to be precise

 
%----------------------------------------------------------------------------------------

%\vfill % Fill the rest of the page with whitespace

\end{titlepage}

\begin{abstract} %begin abstract  
%The abstract should have one page and should be a compact presentation of the dissertation.
\vspace{1.0cm}



Floods are without doubt the most devastating natural disasters, striking numerous regions in the world each year. During the last decades due the increased frequency of heavy rain and a continuously increasing concentration of population near water regions a lot of assets and lives were lost.

That is the reason why a system that can create a flood forecasting is  

To process the resulted images we will use a library in python called GDAL which can handle that specific type of files (.tif)

In the first part we will try to identify the areas nearby the rivers and lakes (because that areas are more likely to be flooded), and in the second part we will try to analyze the images based on the height of each section. The water from the rain will gather in the lower areas, so we can presume that that areas are likely to hold water.

\end{abstract} %end abstract


\newpage{}

\chapter{Introduction} 

\pagenumbering{arabic}
\setcounter{page}{1}


\section{Motivation}
\quad
Water is an essential component of ecosystems for the sustainability of life on our planet. It balances ecosystems and maintains climate variation, carbon cycling, etc. It is equally important to humans and other forms of life. Its excess or absence could lead to disasters and extreme land use change. Hence, identification of water bodies is an essential process in science and engineering research. The identification can be useful in various ways, such as estimation of water areas and demarcation of flooded regions \cite {Rover, Alsdorf}.
\par 

Floods are one of the most devastating natural disasters, striking large regions in the world each year. During the last years due the increased frequency of heavy rain a lot of assets and lives were lost.In general, less developed countries shown the most vulnerability to floods, causing damages that significantly affect the national GDP. At country and community levels important initiatives have and are being devoted to implement appropriate countermeasures, both structural and non-structural, aiming to alleviate the persistent threats of water-related disasters. \cite{Flood-forecasting} 
\par

Flood prediction models are of significant importance for hazard assessment and extreme event management.Robust and accurate prediction contribute highly to water recourse management strategies, analysis, and further evacuation modeling \cite{Xie}.
\par

Thus, the importance of advanced systems for short-term and long-term prediction for flood and other hydrological events is strongly emphasized to alleviate damage \cite{Pitt}. However, the prediction of flood lead time and occurrence location is fundamentally complex due to the dynamic nature of climate condition. Therefore, todayâ€™s major flood prediction models are mainly data-specific and involve various simplified assumptions \cite{Lohani}. 
\par

Physically based models were long used to predict hydrological events, such as storm, rainfall, water flow models, and other global circulation phenomena , including the coupled effects of atmosphere, ocean, and floods. This is the reason why we chose to develop our application based on a physically flood prediction model. Other types of prediction models are data-driven models e.g. machine learning or hybrid models which can combine data-driven, statistical and physically base models.
\par 

Physical models showed great capabilities for predicting a diverse range of flooding scenarios \cite{Nayak},especially in long and mid-term prediction, although they often require various types of geomorphological and  hydrological data. 
\par 

In contrast to the physically based models, the data-driven prediction models using ML shown a higher performance rate on  short-term forecasting compared to the physically based models. In addition,  it was shown that the performance of ML could be improved through hybridization  with other ML methods, soft computing techniques, numerical simulations, and physical models. Such applications provided more robust and efficient models that can effectively learn complex flood systems in an adaptive manner. Although the literature includes numerous evaluation performance analyses of individual ML models \cite{Taherei, Kasiviswanathan, Ravansalar, Mosavi}, there is no definite conclusion reported with regards to which models function better in certain applications. In fact, the literature includes only a limited number of surveys on specific ML methods in specific hydrology fields \cite{Dandagala, Deka, Fotovatikhah}. Consequently, there is a research gap for a comprehensive literature review in the general applications of ML in all flood resource variables from the perspective of ML modeling and data-driven prediction systems.
\par 

Although the data-driven models using ML can be much efficient in some cases there is a still a big draw back regarding their development and use. For a data-driven model to have a high accuracy it will be needed a very large amount of training data, which can be hard to acquire due the weather conditions and monitoring devices availability time. Furthermore the development of a data-driven model using ML is very expensive because it requires a complex model which needs to be trained for a long period of time, requiring a high computation cost, and it also requires a longer validation, testing, and evaluation period.
\par

Even dough the data-driven models using ML can be a great scientific tool they tend to be hard to understood by a non trained person, and they can require, as shown above, a high run cost and a data set which can be very difficult to acquire by every person. This is why we chose to develop a physically prediction model which can be used by everybody with a low run cost, which requires a minimum data-set easy to obtain via different services like Sentinel 1,2,3 or Landsat satellite images programs. This app has the potential to serve regular people when making decisions about where to buy a property, or where to build a house without any risk saving lots of money.
\par


\section{Our Contribution}
\subsection{Method and Outline}

\quad
This paper identifies the state of the art of physically methods for flood prediction taking into account the processing time, cost, efficiency and difficulty to use. The methods that we used shown a very significant performance and accuracy rate.
\par

The applications in flood prediction can be classified according to flood resource variables, i.e. river flow, flood peak discharge, urban flood and plain flood. Among these key influencing flood resource variables, and the spatial examination of the topographical images, the application include the possibility to detect with high accuracy the water surfaces (over 89\% accuracy from all tests).
\par

The mainly methods that we used in the application were the detection of water and flooding a land area based on the topographical images. The water detection was obtained by combining a set of near infrared (or NIR) and green band satellite images, and then applying a method of extraction called normalized difference water index (NDWI). This method is based on the extraction the water bodies taking into account the reflectance property of water.
\par 

After the water has been detected, the land area is filled based on the topographical map of the surface. One of the problems that we encountered here is ,besides the water detection, the fact that the topographical satellite images tend to cover a bigger area than the NIR and green band area from the satellite images, so we had to map the smaller NIR images into the bigger topographical images, but we will discuss this problem and how we solve it in the following chapters. The resulting product of our application is a area that has a high possibility of being flooded during a heavy rainstorm, results that can be achieved using a very low processing time, cost and resources.
\par 

\begin{center}
	\includegraphics[scale=0.6]{application_outline.png} 
	Fig 1
\end{center}

Combining those techniques with an easy to use and understand client interface we managed to create a system that can predict the land areas with a high potential of being flooded. The processing time and cost are reduced because the server part has to go through a set of images only twice, first time to detect the surface water and second time to fill the land area based on the topographic map, so the computations are reduced as low as possible. On the client side, there are big advantages because the set of resources (satellite images) are free and easy to access and the results are easy to understand, making this application ideal for a non trained person.
\par





\subsection{State of Art of Physically models in flood prediction}

\quad
For creating our physically prediction model we chose to use NDWI water extraction technique due its ease use and low processing time. McFeeters \cite{McFeeters} developed the normalized difference water index (NDWI) using the reflectance of the green (band 2) and near-infrared (band 4) bands of Landsat TM (Thematic Mapper). NDWI is one of the most widely used water indices for a variety of applications, including surface water mapping, land cover analyses \cite{Duan, Poulin, Hui} and also it shown great classification accuracy in areas that include shadow and dark surfaces.
\par 

Besides the existence of NDWI index for detecting the water bodies, there are other techniques presented in various papers \cite{Multifractal water analysis, NDWI Comparison} that shown significant results. These methods are the Multifractal analysis of water bodies using Wavelet method and Fluctuation analysis and the detection of water using neural networks. Both of these techniques shown a high accuracy (multifractal analysis shown the best of those two, over 89\%; very similar to the accuracy obtained by our NDWI index), but there are some downsides regarding the neural network water detection. That method shown great results but only on some particular sets of images and it did not provided a proper classification for all radar images. The studies \cite{NDWI Comparison} suggests that the neural network errors may appear due to the high sensitivity to the noise in the images. 
\par 

On short, after our model manages to detect the water areas from a picture it starts to expand these areas taking into account the topography of the land, like a fill bases in the land level. This model is called a physically prediction model and it allows us to create a simply to understand and test model, which will be time and cost efficient. The image has to be processed only two times in a linear manner, first time to detect the water areas with a complexity of O(n) = N , and second time to fill the land area with a complexity that can go up to O(n) = $N^2$. 
\par 

There exists more complex physical models that can take into account more elements, like land water saturation, vegetation type of that area and the volume of rain that will fall over specific areas, but that types of models are more complex, and more expensive both on execution time and on development time. The test and validation part will need to be more complex, and the input required will be harder to gathered up by a simple user. 
\par 

Besides the physically prediction models there are some other forecasting models presented in various papers \cite{Flood forecasting models}, like data driven models based on machine learning and hybrid models that combine physically, and machine learning hydrologically models.\par 

The first one that we will discuss is the \textbf{ML-based hydrology-dynamic modeling}: The computational cost of this model can limit the resolution and the scope of the hydro-dynamic system. The costs can be reduced by up to orders of magnitude by taking advantage of machine learning derivation methods, as it was experimentally done of other fluid dynamics models \cite{Yohai}.
\par 

The second model that we will discuss about will be the \textbf{Remote discharge estimation}: The most important obstacle for incorporating machine learning into the hydrology field is the limited data. Measuring the water levels and the discharges is relatively difficult when it comes into attention the global order of 100,000. But still, the quantity, variety and quality of satellites constantly imaging all river is rising at a very fast pace. The ability to estimate the river discharges without in-site measurements is a a task that has become both critical for the hydrology field, and incredibly well suited for machine learning field.
\par 

The third and the last model that we will discuss about is the \textbf{Hybrid physics-machine learning hydrologic models}: This model is a alternative to the machine learning approach, and it adopts a hybrid approach where a ML model is combined with the classical physics-based components, which can enclose important prior knowledge about the domain structure. Some could view this approach as allowing the physically model to capture the major hydrologic  model, while the ML will be responsible for error correction, and calibration of the final model. As an interesting fact, it was shown that the physically models tend to be more accurate on the long-term and mid-term prediction, while the ML tend to be more accurate on the short-term predictions, and by combining those two techniques in one we can possibly obtain a accurate prediction model on both long-term and short-time periods.



\section{Thesis Structure}



\newpage{}


\chapter{The application}

\section{Technologies used}

\subsection{Collecting and processing the resources}

\subsubsection{Collecting the resources}

\quad
Our prediction model was created with a simple scope in mind, to offer a simply  application that can predict the areas with high risk of being flooded during a rainstorm, with as little processing time and cost as possible. The input for our model had to be easy to obtained and the output had to be easy to understand, so we chose to use a input data that is both easy to obtained and free (it will need to be accessible by every person). The input for our model is a set of .tiff images that should contain a near infrared image (NIR), a green band image, and a topographic image. A simple way to obtain the NIR and green band images is by using the available data offered by satellites like Landsat 1 to Landsat 8 or Sentinel 2. 

\par 
The Landsat project is one of the longest-running enterprise projects for acquisition of satellite imagery of Earth. The project was first developed by NASA and then it was transferred to NOAA (National Oceanic and Atmospheric Administration) by U.S Jimmy Carter's presidential directive. There were 8 Landsat satellites on the Earth's orbit, now only 2 of them are still active, and the resources collected are available on the USGS (U.S Geological Survey) website. The only thing that a user will need in order to access the data is a free account. After the account is created the user can select different areas via USGS's EarthExplorer portal and download the area's satellite imagery using filters like Data Range or satellite preference (Landsat satellite 1-8).
\par

\bigskip

\includegraphics[scale=0.5, right]{landsat_search.png} 
\begin{center}
Fig 2 - \cite{USGS}
\end{center}

The image presented above (fig 2) is a shot taken while searching for our test data from a region in U.S (Cairo) that was heavy flooded during a rainstorm by the Mississippi river. The yellow and pink areas represents two different scenes captured by the Landsat 7 satellite. A set of 8 images are found in a package downloaded from this website depending on the satellite that had provided them, but all the Landsat satellites imagery set contains a NIR and green band shot of the selected area (the main difference between them is the resolution in meters of the photo). We used in our research mainly Landsat's 7 images because the photos are at a higher resolution (30 m) and most of them are already processed by the USGS servers (some images need to be processed by the internal servers before being available to the users).

\includegraphics[scale=0.73, center]{Capture.png} 
\begin{center}
Fig 3 - \cite{Wiki_landsat}
\end{center}


\medskip

As we specified above there is another option to obtain the images besides Landsat, and that is through the Sentinel program. Sentinel is an observation mission from the Eu Copernicus Programme that acquires optical imagery of Earth at large resolution (10 to 60 m) over land and coastal waters. There are 3 satellites launched by the Copernicus Programme but we will focus mainly on Sentinel 2, because it has the largest collected data. 
\par 

The Sentinel 2 satellite has a multi-spectral instrument with 13 spectral channels in the visible, short wave and near infrared spectral range. The bands that are interesting for us are the 3-rd band which is the green one and the 8-th band which is the NIR one (the bands have a spatial resolution of 10 m). The images  can be downloaded from the Copernicus Scihub website, again by creating a free account. There is a possibility to select a date range, cloud coverage in percents and the satellite platform which is the best suitable for the user needs (I.E Sentinel 1,2 or 3). 
\par 

\bigskip

\includegraphics[scale=0.54, center]{sentinel.png} 
\begin{center}
Fig 4 - \cite{Copernicus}
\end{center}
\par 


Still, there are some drawbacks from using the Sentinel imagery. We chose to use the Landsat images over Sentinel's data set, because the Sentinel 1 images are at a lower resolution, and the Sentinel 2 and 3 images are too recent taken (the satellites were launched in 2015, so the data could not cover a larger time period for our data analysis).
\par 

After we obtained the NIR and green band images we will need to download a topographic map of the area ,that will be processed. The topographic map can be taken from USGS website by searching for digital elevation maps. The process is pretty similar to the one of collecting Landsat imagery. A interesting difference between a NIR and a topographic image is represented by the images size. The topographic image is usually taken over a larger field, and this is a problem that we encountered during the processing of the areas with high flood risk. We needed to determine where to place the smaller image inside the bigger one based on coordinates, but we will discuss about this problem in one of the following sections.
\par

\subsubsection{Processing the resources}

\quad
Before a set of images can be processed by our application they need to be rendered. For this process we used a program called QGIS. Qgis is an open source geographic information system, created by OSGeo (Open Source Geospatial Foundation), licensed under GNU, that supports numerous vector, raster and database formats and functionalities \cite{QGIS}.
\par 

The images will need to be rendered from 8 bit depth to 32 bit depth and the pixel range value will be mapped between 0 and 255. They will also need to be saved with .TIF extension, to be later processed by our servers.
\par 

The Sentinel images are pretty straight forward to rendered, but the images from Landsat will need an extra step before being ready to save. The Landsat 7 images have what seems to be "black stripes" across the side of the image. This is due to a failure of Landsat 7 Scan Line Corrector. The forward movement of the satellite on the orbit should be compensated by The Scan Line Corrector, but because of the failure a zigzag pattern of ground tracking is used instead of a mapping in straight lines. This can be seen very clearly in the image below (fig 5), and the location of the black stripes varies between 390-450 m; therefore US Geological Survey(USGS) estimates that affected images lose about 22\% of their data \cite{Landsat-error}.

\bigskip

\includegraphics[scale=0.54, center]{landsat_black_stripes.png} 
\begin{center}
Fig 5
\end{center}
\par 

\quad
The black lines get smaller as we approach the center of the image, which means that we can crop some parts of the land area and use them without any future modification, or if we need to use the full image we can try to apply a image correction, which should fill the black lines based on the gap masks offered by Landsat (for this part we will need to have Gdal installed). Below we can see how a mask layer looks like (fig 6).
\par 


\bigskip

\includegraphics[scale=0.54, center]{landsat_black_stripes_correction.png} 
\begin{center}
Fig 6
\end{center}
\par 

After the images are ready they can be rendered by saving the image with .tif extension and checking the "render image" box.



\section{Programming languages and Frameworks} 

\subsection{Programming language: Java}
\medskip

\quad
Java is popular object-oriented programming language that was designed to have as few implementation dependencies as possible. It was created in 1995 by Sun Microsystems and now it is owned by Oracle.
\par

This project was developed using Java 1.8 with two external libraries i.e.: Gdal and jai-imageio-core 1.4.0. Any version below 1.6 will now work as intended because of jai-imageio-core library. These libraries were used to process the TIFF images from satellite.
\par

At first we intended to use Python as the heavy lifting programming language because of the more relaxed syntactic structure, but in the end we chose Java because of its parallel programming capabilities. Usually when we have to work with satellite images we should take into account the fact that the images can be really large, like 8161x7211 pixels in size covering over 589.000.000 $km^2$, and when we have to process more that one image of this kind the processing time becomes very important.
\par

Python will become much slower in this area because of the Global Interpreter Lock or GIL (a mutex, or a lock, that allows only one thread to be in a state of execution at any point in time). The impact of the GIL is visible only to developers who execute multi-threaded programs, because it can create a performance bottleneck at the CPU level.
 \par
 
\bigskip

In the following image (fig 7) we can take a look over the processing time between the Java's multi-threaded system and the single-threaded Python's system
\par

\bigskip

\begin{center}
Fig 7
\end{center}
\par 
\includegraphics[scale=0.7, center]{multi_thread2.png}

\quad
The tests were made by us on a sample of 8 images with an average size of 1000x1000 px, and the results shown that the java multi-threaded system (marked with blue on fig 7) was in average faster with 40\% than the python single-threaded system. We valued this feature very much because the reduced time of processing combined with the image handling power offered by java helped us to create a time and cost efficient application, and that is what we intended at first.


\subsection{Programming language: Python}
\medskip

\quad
Python is a interpreted, high-level, open source programming language that was made to have a  relaxed syntactic structure and to be more easy to read. It supports both functional and object oriented programming and its mainly targeted to a fast development and easy to maintain code.
\par

Python had played a major role in the project because of its relaxed syntactic structure and it was use to create the server part of the application, using Flask (flask is a microframework for python web based applications).
\par 

After the server receives a set of satellite images from the user, a Java process is started by the server to solve the request. The java files are complied when the server is started for the first time and then for every request a java process is started. All this part was handled using the python's "subprocess" library
\par
\medskip

We will take a short look on how the python server compiles the java files and how a process is started, and we will discuss in more details in the next chapters.
\medskip

Here we can take a short look on how the java files are compiled
\par
\bigskip
\includegraphics[scale=0.8, center]{python_call_java_1.png}
\begin{center}
Fig 8
\end{center}

\newpage

Here we can take a look on how a process is started
\par
\medskip
\includegraphics[scale=0.7, center]{python_call_java_2.png}
\begin{center}
Fig 9
\end{center}

\subsection{Gdal Library}

\quad
Gdal (Geospatial Data Abstraction Library) is a software library available for multiple programming languages (python, java, c++) for manipulating rasters and geospatial data vectors. It was released by the Open Source Geospatial Foundation (OSGeo) in the 2000 year with a permissive X/MIT free software license\cite{Gdal}. 
\par 

We used Gdal as a Java library to process the satellite images. We needed a way to extract the coordinates of specific pixels from .Tif images, and The Gdal library offered a convenient way of doing that by using gdal.Datasets, gdal.Band and the GeoTransform matrix.

\subsection{Flask Framework}

\quad
Flask is a web framework written for Python which is classified as a microframework because it does not require particular tools or libraries, and it is really light weight because it has no database abstraction, no user authentication and no form validation.
\par 

Flask was developed based on the template engines offered by Jinja 2, which can enable a accelerated development for our web application. It also offers a micro but extensible web framework, which can become very flexible by using several widely used web development tools and libraries \cite{Flask1}.
\par 

There is an another available web framework dedicated to Python which we took into consideration when we built this application and that is Django. At first look Django seemed a better choice than Flask, because it has a better template engine than Flask, it has a ORM (object-relational mapping) system that can work with several databases like SQLite, Oracle and MySQL and it has a built-in bootstrapping tool, but despite all this upsides, which can make the application development much easier, there are some drawbacks when using Django. Even though Django could offer a cheaper App development, we should also take a look on how a Django HTTP server will compare to a HTTP Flask server.
\par 

We had to consider the fact that the machine on which our application will run will need to be cheap to maintained, and it should be pretty responsive, which means that it should have a low latency (that was one of our main focuses). We took a look on several benchmarks that compared the performance obtained by Flask and Dajngo during longer sessions of run time, because the available resources tend to change with time. We had to determine how they can handle a more intensive environment where the available resources can decrease. Like on the real machines where the decrease of resource is non linear because the OS can spawn daemons or trigger some side jobs, we had to find some tests that will take this facts into account, and we found that the HTTP Flask server performs much better than the HTTP Django server in this king of conditions. The tests that we take into consideration \cite{Flask2} were made using Gunicorn (a Python Web Server Gateway HTTP interface) at a constant 4000 queries per seconds. In the tests the HTTP Falsk server displayed a lower latency and  error numbers and a higher request number compared to the HTTP Django server.
\par 

\bigskip
\includegraphics[scale=0.7, center]{django-flask-table.png}
\begin{center}
Fig 10 - \cite{Flask2}
\end{center}

\medskip
\includegraphics[scale=0.6, center]{django-flask-latency.png}
\begin{center}
Fig 11 - \cite{Flask2}
\end{center}




\section{Functional description}

\quad
In this section we will take a closer look on how our application manages to process the input offered by the user and predict the areas with high flooding risk. Firstly we offer a friendly and easy to understand web interface where any user can upload a set of satellite images, where a set is composed of a NIR image, a green band image and a topographical image (a user can upload multiple sets of this kind at once; the sets will be identified based on names).
\par 
 After the input is uploaded to the server a solving request will be created and placed on a queue. Each request is processed one at a time, and when it turn will come, the server will unzip the input and start the prediction. The first step in our prediction consists in detecting the water surfaces by combining the NIR band image and the green band image and then applying a formula called NDWI (Normalized Difference Water Index) to each pixel. After that, the resulting image is mapped to the topographical image and a fill algorithm is applied. The fill will start from the water bodies already detected and it will spread base on the land's topography.


\subsection{Detecting surface water using NDWI + referinte si procente}
\quad 

The detection of the water bodies was probably one of the most challenging part of this application, because there are different types of water, with different colors and different densities. At first, we tried to detect the water surfaces based on their color, but usually the chromatic of the oceanic water is very different than the chromatic of the lakes and rivers. The color range that we had to cover was too large, so we gave up on this idea. 
\par 
The second method that we tried was to use only the near infrared band. The idea behind this was that the satellite will shoot a laser beam across the land area and the beam will be reflected back by the most objects, except water. It is one of the only things that can absorb the NIR laser, so the values of the NIR resulted images ,over the water bodies, will be equal to 0. Near the water banks, because the volume of water is too small to absorb all the NIR rays, the pixel values will not be exactly 0 (the value range can vary up to 15-20). The method seemed to work when we considered all the pixel values between 0-15 to be a water part, with a calculated accuracy of around 83\% (from our tests done over a set of 12 images), but we encountered a big drawback. On the flatter land areas, lacking valleys and mountains, the images looked pretty good, but when the topography was to diverse the shadows began to appear. The pixel value of the areas covered by shadows can vary between 10 and 25, so we got a lot of false positive cases.

\bigskip
\includegraphics[scale=0.4, left]{water-false-positive.png}
\begin{center}
Fig 12 - False positive water detection
\end{center}
\par 

We can take a look in the previous picture (Fig 12) to see how significant are the errors caused by the shadows. The green areas represent the water bodies classified correct and the white areas are the shadows that our application classified as water. It may not seem much but that figure is 1414 x 658 pixels in size covering around 930.412 $m^2$, and it will be a waist of money to move all the people from that areas in case of a flood just because we classified the shadows as water.
\par 

The method that we chose in the end was to use a index called NDWI or Normalized difference water index. NDWI is a remote sensing indicator which is obtained by combining the NIR and green band images. The formula will be applied as following for each pixel:

$$ NDWI/perpixel = \frac{Xgreen - Xnir}{Xgreen + Xnir}$$

If the calculated value is bigger than 0.45 we can classify that specific pixel as a spot that contains water, and all the other values below that can be classified as non-water pixels (land). This method shown a very satisfying result compared to the true value, with an calculated accuracy of around 88\% (the tests were done by us over a set of 12 images; over the oceanic area the accuracy was around 98\% and over the more diverse land area the accuracy was around 82\%). The big advantage of this approach was that it dose not identify any shadows as water pixels, without losing the accuracy. 
\par 
There are numerous studies \cite{NDWI, NDWI Comparison} that suggested that NDWI is one of the best classification method, for optical images, comparable with the multifractal formalism method (with an accuracy of 89\%), and the neural network classification approach that shown great results in some cases, but it did not provide a proper classification because of its high sensitivity to speckle noise.
\par 

In the end, using this approach we manage to detect all the water bodies with a great accuracy with a insignificant false positives like shadows and other objects. We can take a look in the following picture (Fig 13) on how a result image using NDWI would look like. In this picture all the white zones are water areas, and if we make a difference between the Fig 12 and Fig 13 we can see a big improve when we take in consideration the error caused by the shadows.
\par 


\bigskip
\includegraphics[scale=0.4, left]{NDWI-prediction.png}
\begin{center}
Fig 13 - Water detection using NDWI (white areas are water bodies)
\end{center}
\par 

After the application has managed to detect all the water bodies from a image it will need to overlay the processed image over the topographic image. This will be a topic that we will cover in the next subsection.

\subsection{Mapping the processed images (containing water) to the topographically images}

\quad
In this section we will discuss about how we managed to map two images (the processed image, containing water, with the topographical image). The idea behind this process is that, usually the topographical images available online tend to cover a very large area, that can be even 10 times bigger that the image from which we detect the water bodies, so when we apply the fill algorithm that should extend the water areas based on the topographical surface we cannot just simply place the smaller image over the larger one without taking into account the coordinates. 
\par 

Fortunately for us, every topographical, NIR, and green band image offered both by Landsat and Sentinel has a header that contains the metadata (information about the data; structural, administrative and descriptive) for that specific image. In the header we can find the coordinates of each corner of an image, and we can use the Gdal library to take use of that data. 




\subsection{fill imagine}




\chapter{The application}

\section{Qgis introduction} 


\section{Python GDAL introduction} 

\section{Functional description} 


\section{The user interface}


\section{Main use cases}


\section{Implementation details}

\newpage



\newpage{}

\chapter{Conclusions}


\section{Performance Evaluation} 


\section{Future Development}


\renewcommand{\bibname}{Bibliography}

\bibliographystyle{Plain} % Plain, Abbrv, Unsrt, Alpha
\addcontentsline{toc}{chapter}{Bibliography} 

\begin{thebibliography} {10}

%\begin{thebibliography}{widest entry}
\bibitem{Rover} Rover J., Ji L., Wylie B.K., Tieszen L.L. Establishing Water Body Areal Extent Trends in Interior Alaska from Multi-Temporal Landsat Data. Remote Sens. Lett. 2012;3:595â€“604. doi: 10.1080/01431161.2011.643507

\bibitem{Alsdorf} Alsdorf D.E., RodrÃ­guez E., Lettenmaier D.P. Measuring Surface Water from Space. Rev. Geophys. 2007;45 doi: 10.1029/2006RG000197. [CrossRef] [Google Scholar]

\bibitem{Flood-forecasting}
Flood forecasting - World meteorological organization \textit{http://www.wmo.int/pages/prog/hwrp/FloodForecastingInitiative.php} - accessed in 15.05.2019


\bibitem{Xie} Xie, K; Ozbay,K;Zhu, Y;Yang, H. Evacuation zone modeling under climate change: A data-driven method. J.Infrastruct. Syst. 2017,23,04017013

\bibitem{Pitt}Pitt, M.	Learning Lessons from the 2007 Floods; Cabinet Office: London, UK, 2008.

\bibitem{Lohani}Lohani, A.K.; Goel, N.; Bhatia, K. Improving real time flood forecasting using fuzzy inference system.J. Hydrol. 2014, 509, 25â€“41

\bibitem{Nayak}Nayak, P.; Sudheer, K.; Rangan, D.; Ramasastri, K. Short-term flood forecasting with a neurofuzzy model.Water Resour. Res. 2005, 41.

\bibitem{Taherei}Taherei Ghazvinei, P.; Hassanpour Darvishi, H.; Mosavi, A.; Yusof, K.B.W.; Alizamir, M.; Shamshirband, S.; Chau, K.W. Sugarcane growth prediction based on meteorological parameters using extreme learning machine and artificial neural network. Eng. Appl. Comput. Fluid Mech. 2018, 12, 738â€“749

\bibitem{Kasiviswanathan}Kasiviswanathan, K.; He, J.; Sudheer, K.; Tay, J.-H. Potential application of wavelet neural network ensemble to forecast streamflow for flood management. J. Hydrol. 2016, 536, 161â€“173.

\bibitem{Ravansalar}Ravansalar, M.; Rajaee, T.; Kisi, O. Wavelet-linear genetic programming: A new approach for modeling monthly streamflow. J. Hydrol. 2017, 549, 461â€“475.

\bibitem{Mosavi}Mosavi, A.; Rabczuk, T. Learning and intelligent optimization for material design innovation. In Learning and Intelligent Optimization; Springer: Cham, Switzerland, 2017; pp. 358â€“363.

\bibitem{Dandagala}Dandagala, S.; Reddy, M.S.; Murthy, D.S.; Nagaraj, G. Artificial neural networks applications in groundwater hydrologyâ€”A review. Artif. Intell. Syst. Mach. Learn. 2017, 9, 182â€“187.

\bibitem{Deka}Deka, P.C. Support vector machine applications in the field of hydrology: A review. Appl. Soft Comput. 2014,
19, 372â€“386.

\bibitem{Fotovatikhah}Fotovatikhah, F.; Herrera, M.; Shamshirband, S.; Chau, K.-W.; Faizollahzadeh Ardabili, S.; Piran, M.J. Survey of computational intelligence as basis to big flood management: Challenges, research directions and future work. Eng. Appl. Comput. Fluid Mech. 2018, 12, 411â€“437. 

\bibitem{McFeeters}McFeeters, S.K. The use of the normalized difference water index (NDWI) in the delineation of open water features. Int. J. Remote Sens. 1996, 17, 1425â€“1432.

\bibitem{Duan}Duan, Z.; Bastiaanssen, W.G.M. Estimating water volume variations in lakes and reservoirs from four operational satellite altimetry databases and satellite imagery data. Remote Sens. Environ. 2013, 134, 403â€“416.

\bibitem{Poulin}Poulin, B.; Davranche, A.; Lefebvre, G. Ecological assessment of phragmites australis wetlands using multi-season spot-5 scenes. Remote Sens. Environ. 2010, 114, 1602â€“1609..

\bibitem{Hui}Hui, F.; Xu, B.; Huang, H.; Yu, Q.; Gong, P. Modelling spatial-temporal change of poyang lake using multitemporal landsat imagery. Int. J. Remote Sens. 2008, 29, 5767â€“5784.

\bibitem{Multifractal water analysis}
Multifractal Analysis of Hydrologic Data -
Tongzhou Zhao, Liang Wu, Dehua Li, Yiming Ding, Multifractal Analysis of Hydrologic Data Using Wavelet Methods and Fluctuation Analysis, published in Discrete Dynamics in Nature and Society
Volume 2017

\bibitem{NDWI Comparison}
Comparison between NDWI, Machine Learning, and Multifractal analysis for detecting water bodies -  
V. M. San Martina, Alejandra Figliolaa, Application of Multifractal Analysis to Segmentation of WaterBodies in Optical and Synthetic Aperture Radar Satellite Images, originally announced April 2016 and published in Cornell University Journal.

\bibitem{Flood forecasting models}
Flood forecasting models - S. Nevo, V. Anisimov, G. Elidan, R. El-Yaniv, P. Giencke, Y. Gigi, A. Hassidim, Z. Moshe, M. Schlesinger, G. Shalev, A. Tirumali, A. Wiesel, O. Zlydenko, Y. Matias ,  ML for Flood Forecasting at Scale originally announced in January 2019, published in 28 January 2019 on arXiv.

\bibitem{Yohai}
ML hydro-dynamic modeling
Yohai Bar-Sinai, Stephan Hoyer, Jason Hickey, and Michael P Brenner. Data-driven discretiza-tion: a method for systematic coarse graining of partial differential equations.arXiv preprintarXiv:1808.04930, 2018


\bibitem{USGS}
USGS \textit{https://earthexplorer.usgs.gov/} - accessed in 19.05.2019


\bibitem{Wiki_landsat}
Wikipedia Landsat Program \textit{https://en.wikipedia.org/wiki/Landsat\_program} - accessed in 19.05.2019

\bibitem{Copernicus}
Copernicus \textit{https://scihub.copernicus.eu/} - accessed in 19.05.2019

\bibitem{QGIS}
QGIS \textit{https://www.qgis.org/en/site/about/index.html} - accessed in 19.05.2019

\bibitem{Landsat-error}
Landsat-error \textit{https://www.pixalytics.com/landsat-quirks/} - accessed in 22.05.2019

\bibitem{Gdal}
Gdal \textit{https://en.wikipedia.org/wiki/GDAL} -accessed in 22.05.2019

\bibitem{Flask1}
Flask vs Django \textit{http://www.mindfiresolutions.com/blog/2018/05/flask-vs-django/} -accessed in 22.05.2019

\bibitem{Flask2}
Flask server vs Django server \textit{http://blog.gmludo.eu/2015/02/macro-benchmark-with-django-flask-and-asyncio.html} -accessed in 22.05.2019

\bibitem{NDWI}
A. S. Rogers, M. S. Kearney, Reducing signature variability in unmixing coastal marshthematic mapper scenes using spectral indices, International Journal of Remote Sensing25 (12) (2004) 2317â€“2335.






\end{thebibliography}






% end appendix part

\end{document}
